{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ml_assemblr.main_components.data_pod import DataPod\n",
    "from ml_assemblr.main_components.data_pod_list import DataPodList\n",
    "from home_credit_helper.config import cfg\n",
    "from home_credit_helper.constant import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_assemblr.transfromer.column_type.features_setter import TopDownFeaturesSetter\n",
    "from ml_assemblr.transfromer.column_type.column_type_setter import ColumnTypeSetter\n",
    "from ml_assemblr.transfromer.cross_validator.cross_validator import CrossValidator, get_cv_folds\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cfg.research_cache_path / \"03_dp.pkl\", \"rb\") as f:\n",
    "    dp: DataPod = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_path = cfg.research_cache_path / \"06_selected_features.pkl\"\n",
    "is_full_features = not os.path.exists(selected_features_path)\n",
    "\n",
    "if not is_full_features:\n",
    "    with open(selected_features_path, \"rb\") as f:\n",
    "        selected_features: list[str] = pickle.load(f)\n",
    "    \n",
    "    feature_setters = ColumnTypeSetter(column_type_map={\"features\": selected_features})\n",
    "else:\n",
    "    feature_setters = TopDownFeaturesSetter()\n",
    "\n",
    "dp = dp.fit_transform(feature_setters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config hyperparams tuning\n",
    "\n",
    "study_name_suffix = \"-supset-features\"\n",
    "\n",
    "eval_metric = 'auc'\n",
    "is_maximize_metric = True\n",
    "xgb_training_objective=\"binary:logistic\"\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "optuna_study_path = f\"sqlite:///{cfg.research_cache_path / \"optuna_studies.db\"}\"\n",
    "# optuna_study_path = \"sqlite:///.cache/optuna_studies.db\"\n",
    "study_name = \"xgb-hyperparam-tuning\" + study_name_suffix\n",
    "sampler = TPESampler(n_startup_trials=40)\n",
    "pruner = MedianPruner(n_warmup_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = CrossValidator(sklearn_cv=ShuffleSplit(n_splits=3, test_size=0.2, random_state=42))\n",
    "dp = dp.fit_transform(cross_validator)\n",
    "folds = get_cv_folds(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dp.slice_df(split=set([\"train\", \"valid\"]), columns=None, table_name=APPLICATIONS)\n",
    "feature_cols = dp.main_column_type.features\n",
    "label_col = dp.main_column_type.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(df[feature_cols], label=df[label_col[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial):\n",
    "    params = dict(\n",
    "        # first tier\n",
    "        learning_rate=trial.suggest_float(\"param_learning_rate\", 0.00001, 1),\n",
    "        max_depth=trial.suggest_int(\"param_max_depth\", 1, 10),\n",
    "        subsample=trial.suggest_float(\"param_subsample\", 0.2, 1.0),\n",
    "        objective=xgb_training_objective,\n",
    "        # second tier\n",
    "        num_parallel_tree=trial.suggest_int(\"param_num_parallel_tree\", 1, 10),\n",
    "        min_child_weight=trial.suggest_float(\"param_min_child_weight\", 0, 20),\n",
    "        max_delta_step=trial.suggest_float(\"param_max_delta_step\", 0, 10),\n",
    "        colsample_bylevel=trial.suggest_float(\"param_colsample_bylevel\", 0, 1),\n",
    "        colsample_bynode=trial.suggest_float(\"param_colsample_bynode\", 0, 1),\n",
    "        colsample_bytree=trial.suggest_float(\"param_colsample_bytree\", 0, 1),\n",
    "        min_split_loss=trial.suggest_float(\"param_min_split_loss\", 0, 5),\n",
    "        max_leaves=trial.suggest_int(\"param_max_leaves\", 3, 50),\n",
    "        reg_alpha=trial.suggest_float(\"param_reg_alpha\", 0, 5),\n",
    "        reg_lambda=trial.suggest_float(\"param_reg_lambda\", 0, 5),\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"eval_metric\", eval_metric)\n",
    "    trial.set_user_attr(\"param_objective\", xgb_training_objective)\n",
    "\n",
    "    num_rounds = trial.suggest_int(\"num_rounds\", 20, 500, log=False)\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, f\"test-{eval_metric}\")\n",
    "\n",
    "    cv_results: pd.DataFrame = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        folds=folds,\n",
    "        num_boost_round=num_rounds,\n",
    "        metrics=eval_metric,\n",
    "        callbacks=[pruning_callback],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        maximize=is_maximize_metric,\n",
    "        verbose_eval=False,\n",
    "        as_pandas=True,\n",
    "    )\n",
    "\n",
    "    best_iter = int(cv_results[f\"test-{eval_metric}-mean\"].argmax())\n",
    "\n",
    "    trial.set_user_attr(\"is_maximize_metric\", is_maximize_metric)\n",
    "\n",
    "    trial.set_user_attr(\"num_rounds\", best_iter)\n",
    "    trial.set_user_attr(\n",
    "        \"train_metric_mean_at_trial_end\",\n",
    "        float(cv_results[f\"train-{eval_metric}-mean\"].iloc[best_iter]),\n",
    "    )\n",
    "    trial.set_user_attr(\n",
    "        \"train_std_at_trial_end\",\n",
    "        float(cv_results[f\"train-{eval_metric}-std\"].iloc[best_iter]),\n",
    "    )\n",
    "    trial.set_user_attr(\n",
    "        \"val_std_at_trial_end\",\n",
    "        float(cv_results[f\"test-{eval_metric}-std\"].iloc[best_iter]),\n",
    "    )\n",
    "\n",
    "    metric = float(cv_results[f\"test-{eval_metric}-mean\"].iloc[best_iter])\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 22:18:30,767] Using an existing study with name 'xgb-hyperparam-tuning-supset-features' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    storage=optuna_study_path,\n",
    "    study_name=study_name,\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100,\n",
    "    n_jobs=2,\n",
    "    # n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_learning_rate': 0.20072683838790215,\n",
       " 'param_max_depth': 10,\n",
       " 'param_subsample': 0.7148295489790479,\n",
       " 'param_num_parallel_tree': 7,\n",
       " 'param_min_child_weight': 8.100500759676423,\n",
       " 'param_max_delta_step': 9.857091261659203,\n",
       " 'param_colsample_bylevel': 0.4826516588867641,\n",
       " 'param_colsample_bynode': 0.7289133194453435,\n",
       " 'param_colsample_bytree': 0.7238114214160121,\n",
       " 'param_min_split_loss': 0.524271049652073,\n",
       " 'param_max_leaves': 34,\n",
       " 'param_reg_alpha': 1.3968990877191585,\n",
       " 'param_reg_lambda': 2.885833987262361,\n",
       " 'num_rounds': 245}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_metric': 'auc',\n",
       " 'is_maximize_metric': True,\n",
       " 'num_rounds': 209,\n",
       " 'param_objective': 'binary:logistic',\n",
       " 'train_metric_mean_at_trial_end': 0.8956501191099603,\n",
       " 'train_std_at_trial_end': 0.00037159148216916153,\n",
       " 'val_std_at_trial_end': 0.0012020103476224286}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.user_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7866482656529904]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial._values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-home-credit-default-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
